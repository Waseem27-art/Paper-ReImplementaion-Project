{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length_url  length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  \\\n",
      "0          37               19   0        3           0      0      0       0   \n",
      "1          77               23   1        1           0      0      0       0   \n",
      "2         126               50   1        4           1      0      1       2   \n",
      "3          18               11   0        2           0      0      0       0   \n",
      "4          55               15   0        2           2      0      0       0   \n",
      "\n",
      "   nb_or  nb_eq  ...  suspecious_tld  statistical_report  \\\n",
      "0      0      0  ...               0                   0   \n",
      "1      0      0  ...               0                   0   \n",
      "2      0      3  ...               0                   0   \n",
      "3      0      0  ...               0                   0   \n",
      "4      0      0  ...               0                   0   \n",
      "\n",
      "   whois_registered_domain  domain_registration_length  domain_age  \\\n",
      "0                        0                          45          -1   \n",
      "1                        0                          77        5767   \n",
      "2                        0                          14        4004   \n",
      "3                        0                          62          -1   \n",
      "4                        0                         224        8175   \n",
      "\n",
      "   web_traffic  dns_record  google_index  page_rank  is_phishing  \n",
      "0            0           1             1          4            0  \n",
      "1            0           0             1          2            1  \n",
      "2      5828815           0             1          0            1  \n",
      "3       107721           0             0          3            0  \n",
      "4         8725           0             0          6            0  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "           feature type  mutable   min     max\n",
      "0       length_url  int     True  12.0  1641.0\n",
      "1  length_hostname  int     True   4.0   214.0\n",
      "2               ip  int     True   0.0     1.0\n",
      "3          nb_dots  int     True   1.0    24.0\n",
      "4       nb_hyphens  int     True   0.0    43.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load the URL dataset\n",
    "url_data = pd.read_csv('url/url.csv')\n",
    "\n",
    "# Check the data\n",
    "print(url_data.head())\n",
    "\n",
    "# Load metadata\n",
    "url_metadata = pd.read_csv('url/url_metadata.csv')\n",
    "\n",
    "# Inspect metadata (for feature info)\n",
    "print(url_metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and target (y)\n",
    "X = url_data.drop(columns=['is_phishing'])  # Features (exclude target)\n",
    "y = url_data['is_phishing']  # Target variable (is phishing)\n",
    "\n",
    "# Handle missing values by imputing with the mean for numerical columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Further validation if needed (cross-validation for robust training)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9343797025371829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train a classifier (you can replace this with any other model)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 1 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 1 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 2 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 2 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 2 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 3 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 3 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 3 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 4 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 4 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 4 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 5 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 5 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 5 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 6 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 6 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 6 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 7 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 7 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 7 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 8 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 8 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 8 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 9 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 9 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 9 - Accuracy on Adversarial Data: 0.9386876640419947\n",
      "Epoch 10 started.\n",
      "Model Accuracy on Adversarial Data: 0.7713254593175853\n",
      "Epoch 10 - Accuracy on Clean Data: 0.9386876640419947\n",
      "Epoch 10 - Accuracy on Adversarial Data: 0.9346876640419947\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def clip(x, lower_bound, upper_bound):\n",
    "    \"\"\"\n",
    "    Clips the adversarial example to make sure it stays within the allowed bounds.\n",
    "    \"\"\"\n",
    "    return np.clip(x, lower_bound, upper_bound)\n",
    "\n",
    "def generate_adversarial_sample(model, X_sample, y_sample, metadata, epsilon=1, maxiters=20, alpha=0.01, lambda_=0.1, weights=None):\n",
    "    \"\"\"\n",
    "    Generates an adversarial sample for a given data point using the LowProFool attack.\n",
    "    This function is parallelizable.\n",
    "    \"\"\"\n",
    "    r = np.zeros_like(X_sample)\n",
    "    orig_pred = model.predict(X_sample)\n",
    "    loop_i = 0\n",
    "    best_pert_x = X_sample.copy()\n",
    "    best_norm_weighted = np.inf\n",
    "    \n",
    "    while loop_i < maxiters:\n",
    "        # Compute the model output for the perturbed sample\n",
    "        perturbed_sample = X_sample + r\n",
    "        output_pred = model.predict(perturbed_sample)\n",
    "\n",
    "        # Set target label (assuming binary classification with flipped labels)\n",
    "        target = 1 - orig_pred  # Flip the target class\n",
    "\n",
    "        # Compute the loss: cross-entropy loss + L2 regularization term (simplified for this example)\n",
    "        loss_1 = 0 if output_pred == target else 1  # Misclassification penalty (simplified)\n",
    "        loss_2 = np.linalg.norm(r * weights)  # L2 norm penalty\n",
    "        loss = loss_1 + lambda_ * loss_2\n",
    "\n",
    "        # Compute gradient of the loss with respect to the perturbation (simplified)\n",
    "        grad_r = np.sign(r) * loss_2  # Placeholder gradient (in practice, you would compute this numerically)\n",
    "\n",
    "        # Apply perturbation in the direction of the negative gradient\n",
    "        ri = -grad_r * alpha  # Scale the gradient by alpha\n",
    "\n",
    "        # Update the perturbation\n",
    "        r += ri\n",
    "\n",
    "        # Clip perturbation to ensure it's within the feature bounds\n",
    "        r = clip(r, 0, epsilon)\n",
    "\n",
    "        # Update the adversarial example\n",
    "        xprime = X_sample + r\n",
    "\n",
    "        # Check if adversarial example fools the model and has a lower norm\n",
    "        if output_pred != orig_pred and np.sum(np.abs(r * weights)) < best_norm_weighted:\n",
    "            best_norm_weighted = np.sum(np.abs(r * weights))\n",
    "            best_pert_x = xprime\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    # Final clipping to ensure example stays within bounds\n",
    "    best_pert_x = clip(best_pert_x, 0, epsilon)\n",
    "    \n",
    "    return best_pert_x\n",
    "\n",
    "def lowprofool_attack(model, X, y, metadata, epsilon=1, maxiters=20, alpha=0.01, lambda_=0.1, batch_size=32, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    This function generates adversarial examples using the LowProFool approach in a parallelized manner.\n",
    "    \"\"\"\n",
    "    # Feature weights (importance) initialized from metadata or a default value\n",
    "    weights = np.ones(X.shape[1])\n",
    "    orig_pred = model.predict(X)\n",
    "\n",
    "    # Use joblib to parallelize the adversarial sample generation\n",
    "    adversarial_samples = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(generate_adversarial_sample)(model, X[i:i+1], y[i:i+1], metadata, epsilon, maxiters, alpha, lambda_, weights)\n",
    "        for i in range(X.shape[0])\n",
    "    )\n",
    "\n",
    "    # Convert the result into a numpy array\n",
    "    adversarial_samples = np.vstack(adversarial_samples)\n",
    "\n",
    "    # Evaluate model on adversarial examples\n",
    "    y_adv_pred = model.predict(adversarial_samples)\n",
    "    print(f\"Model Accuracy on Adversarial Data: {accuracy_score(y, y_adv_pred)}\")\n",
    "\n",
    "    return adversarial_samples, y_adv_pred\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is a trained RandomForestClassifier and `X_train`, `y_train`, and `url_metadata` are available\n",
    "\n",
    "for epoch in range(10):  # Set the number of epochs as needed\n",
    "    print(f\"Epoch {epoch + 1} started.\")\n",
    "    \n",
    "    # Train on clean data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate adversarial data using batch processing and parallelization\n",
    "    X_adv, _ = lowprofool_attack(model, X_train, y_train, url_metadata, batch_size=64, n_jobs=-1)\n",
    "    \n",
    "    # Train on adversarial data (this can be done on the same model for simplicity)\n",
    "    model.fit(X_adv, y_train)\n",
    "    \n",
    "    # Optionally evaluate model after each epoch\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy on Clean Data: {accuracy_score(y_train, y_train_pred)}\")\n",
    "    \n",
    "    # Evaluate on adversarial data as well\n",
    "    y_train_pred_adv = model.predict(X_adv)\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy on Adversarial Data: {accuracy_score(y_train, y_train_pred_adv)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def clip(x, lower_bounds, upper_bounds):\n",
    "    \"\"\"\n",
    "    Clips adversarial examples to feature-wise bounds.\n",
    "    \"\"\"\n",
    "    return np.minimum(np.maximum(x, lower_bounds), upper_bounds)\n",
    "\n",
    "def generate_adversarial_sample(model, X_sample, y_sample, metadata, epsilon=1, maxiters=20, alpha=0.01, lambda_=0.1, weights=None):\n",
    "    \"\"\"\n",
    "    Generates an adversarial sample for a given data point.\n",
    "    \"\"\"\n",
    "    r = np.zeros_like(X_sample)\n",
    "    orig_pred = model.predict(X_sample)\n",
    "    best_pert_x = X_sample.copy()\n",
    "    best_norm_weighted = np.inf\n",
    "    loop_i = 0\n",
    "\n",
    "    # Get feature bounds from metadata\n",
    "    lower_bounds = metadata[\"lower_bounds\"]\n",
    "    upper_bounds = metadata[\"upper_bounds\"]\n",
    "\n",
    "    while loop_i < maxiters:\n",
    "        perturbed_sample = X_sample + r\n",
    "        output_pred = model.predict(perturbed_sample)\n",
    "        target = (orig_pred + 1) % model.n_classes_  # Multi-class example\n",
    "\n",
    "        loss_1 = 0 if output_pred == target else 1\n",
    "        loss_2 = np.linalg.norm(r * weights)\n",
    "        loss = loss_1 + lambda_ * loss_2\n",
    "\n",
    "        grad_r = np.sign(r) * alpha  # Simplified; replace with proper computation if possible\n",
    "        r -= grad_r\n",
    "        r = clip(r, -epsilon, epsilon)\n",
    "\n",
    "        xprime = X_sample + r\n",
    "        xprime = clip(xprime, lower_bounds, upper_bounds)\n",
    "\n",
    "        if output_pred != orig_pred and np.sum(np.abs(r * weights)) < best_norm_weighted:\n",
    "            best_norm_weighted = np.sum(np.abs(r * weights))\n",
    "            best_pert_x = xprime\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    return best_pert_x\n",
    "\n",
    "def lowprofool_attack(model, X, y, metadata, epsilon=1, maxiters=20, alpha=0.01, lambda_=0.1, batch_size=32, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples using LowProFool in parallel.\n",
    "    \"\"\"\n",
    "    weights = metadata.get(\"weights\", np.ones(X.shape[1]))\n",
    "    lower_bounds = metadata[\"lower_bounds\"]\n",
    "    upper_bounds = metadata[\"upper_bounds\"]\n",
    "\n",
    "    adversarial_samples = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(generate_adversarial_sample)(\n",
    "            model, X[i:i+1], y[i:i+1], metadata, epsilon, maxiters, alpha, lambda_, weights\n",
    "        )\n",
    "        for i in range(X.shape[0])\n",
    "    )\n",
    "\n",
    "    adversarial_samples = np.vstack(adversarial_samples)\n",
    "    y_adv_pred = model.predict(adversarial_samples)\n",
    "    print(f\"Model Accuracy on Adversarial Data: {accuracy_score(y, y_adv_pred)}\")\n",
    "\n",
    "    return adversarial_samples, y_adv_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyberus_ml_security",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
